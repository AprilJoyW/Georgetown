{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1 Review the source code of the webpage using the inspector tool of your browser. \n",
    "List three types of HTML tags you found on the page and explain what elements of the page are created with those tags.\n",
    "I found the following tags head, meta, title. Title contains the title of the page. Meta contains information about the text, like the font type. Head formats the area as a header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2 Issue a request for the webpage using the requests library and display the HTTP response code for the request. \n",
    "What is the response status code and what does it indicate? What do status codes in the 400s mean? What do status codes in the 500s mean?\n",
    "\n",
    "Response status 200 = request completed okay\n",
    "Response status 400s = client error\n",
    "Response status 500s = server error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"https://en.wikipedia.org/wiki/Georgetown_University\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3 Extract all the content with p tag and save as a list\n",
    "Extract all raw text contained in paragraph tags on the web page. Store the results in single cell in a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n Georgetown University is a private Jesuit r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  \\n Georgetown University is a private Jesuit r..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 Pass URL\n",
    "html = requests.get(\"https://en.wikipedia.org/wiki/Georgetown_University\").text\n",
    "\n",
    "# 2 Make it soup object\n",
    "soup_msba = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "msba_p = [each.text for each in soup_msba.find_all(\"p\")]\n",
    "\n",
    "# Convert list of content to dataframe\n",
    "df = pd.DataFrame(msba_p,\n",
    "                 columns=[\"text\"])\n",
    "df = pd.DataFrame({\"text\":\" \".join(df[\"text\"])},\n",
    "                 index=[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4 Load and instantiate a spaCy NLP pipeline. Apply the pipeline to the scraped text to extract the named entities via named entity recognition (NER). Store the results in a new dataframe called ner_df with two columns: the extracted entities/text and its corresponding entity label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "#import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpspacy = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "doc = nlpspacy(df[\"text\"][0])\n",
    "\n",
    "#for each in doc.ents:\n",
    " #   print(each.text, each.label_)\n",
    "    \n",
    "ner_df = pd.DataFrame({\n",
    "    \"text\":[each.text for each in doc.ents],\n",
    "    \"label\":[each.label_ for each in doc.ents]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5 Print in descending order the top 10 most frequently mentioned people and the number of times each is mentioned. Print in descending order the top 10 most frequently mentioned organizations and the number of times each is mentioned. \n",
    "\n",
    "Most mentioned person- Jesus\n",
    "Org- Georgetown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Georgetown University</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jesuit</td>\n",
       "      <td>NORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Georgetown</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D.C.</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>the Centers for Disease Control and Prevention</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>Robert R. Redfield,[335] NASA</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>John-David</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>National Medal of Science</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>Solomon H. Snyder[337</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1286 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   label\n",
       "0                              Georgetown University     ORG\n",
       "1                                             Jesuit    NORP\n",
       "2                                         Georgetown     GPE\n",
       "3                                         Washington     GPE\n",
       "4                                               D.C.     GPE\n",
       "...                                              ...     ...\n",
       "1281  the Centers for Disease Control and Prevention     ORG\n",
       "1282                   Robert R. Redfield,[335] NASA  PERSON\n",
       "1283                                      John-David  PERSON\n",
       "1284                       National Medal of Science     ORG\n",
       "1285                           Solomon H. Snyder[337  PERSON\n",
       "\n",
       "[1286 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df_orgs= ner_df.query('label ==\"ORG\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text\n",
       "Georgetown                             58\n",
       "Georgetown University                  19\n",
       "NCAA                                    7\n",
       "the McDonough School of Business        4\n",
       "SFS                                     4\n",
       "the School of Foreign Service           4\n",
       "The School of Foreign Service           4\n",
       "Georgetown College                      4\n",
       "the Walsh School of Foreign Service     3\n",
       "the School of Continuing Studies        3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orgs = ner_df_orgs['text'].value_counts(ascending=False)\n",
    "orgs.nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text\n",
       "Jesus                  3\n",
       "DeGioia                2\n",
       "Dahlgren Quadrangle    2\n",
       "Hilltoss               2\n",
       "Laura Chinchilla       2\n",
       "Antonin Scalia         2\n",
       "Burleith               2\n",
       "George Tenet           2\n",
       "Alpha Kappa Psi        2\n",
       "Alpha Phi Omega        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df_people= ner_df.query('label ==\"PERSON\"')\n",
    "people = ner_df_people['text'].value_counts(ascending=False)\n",
    "people.nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 Do #3, #4, and #5 again but instead extract all text contained within anchor (<a>) tags on the web page. Do the results differ from the results in #5?\n",
    "    \n",
    "    Yes! The results do change from #5. \n",
    "    Top \"person\" Articles  followed by John Carroll \n",
    "    Top org Georgetown University\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text\n",
       "Georgetown University           23\n",
       "Georgetown                      10\n",
       "GU                               6\n",
       "U.S. News & World Report         5\n",
       "Articles                         5\n",
       "NCAA                             4\n",
       "The Georgetown Voice             4\n",
       "House                            4\n",
       "The Washington Post Archived     3\n",
       "The Washington Post              3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msba_p = [each.text for each in soup_msba.find_all(\"a\")]\n",
    "\n",
    "# Convert list of content to dataframe\n",
    "df = pd.DataFrame(msba_p,\n",
    "                 columns=[\"text\"])\n",
    "df = pd.DataFrame({\"text\":\" \".join(df[\"text\"])},\n",
    "                 index=[0])\n",
    "df\n",
    "doc = nlpspacy(df[\"text\"][0])\n",
    "\n",
    "#for each in doc.ents:\n",
    " #   print(each.text, each.label_)\n",
    "    \n",
    "ner_df = pd.DataFrame({\n",
    "    \"text\":[each.text for each in doc.ents],\n",
    "    \"label\":[each.label_ for each in doc.ents]\n",
    "})\n",
    "ner_df_orgs= ner_df.query('label ==\"ORG\"')\n",
    "orgs = ner_df_orgs['text'].value_counts(ascending=False)\n",
    "orgs.nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text\n",
       "Articles                 11\n",
       "John Carroll              3\n",
       "Gaston Hall               3\n",
       "John J. DeGioia           3\n",
       "Bill Clinton              3\n",
       "Patrick Francis Healy     3\n",
       "James Madison             2\n",
       "Laura Chinchilla          2\n",
       "Antonin Scalia            2\n",
       "Martha                    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df_people= ner_df.query('label ==\"PERSON\"')\n",
    "people = ner_df_people['text'].value_counts(ascending=False)\n",
    "people.nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7 Briefly explain web scraping and named entity recognition/extraction in a way that a non-technical co-worker would understand. \n",
    "\n",
    "Webscraping is a process that reads the base code for a website and converts it into a usable file. Entity recognition takes web scraping a step further and attempts to classify items into categories like names or locations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
